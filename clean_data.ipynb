{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "books_data = pd.read_csv('data/books_data.csv', nrows = 10000)\n",
    "books_ratings = pd.read_csv('data/books_rating.csv', nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'description', 'authors', 'published_date', 'categories']\n",
      "['title', 'user_id', 'helpfulness', 'score', 'summary', 'text']\n"
     ]
    }
   ],
   "source": [
    "# Titles\n",
    "books_data_1 = books_data.drop(['image', 'previewLink', 'infoLink', 'publisher', 'ratingsCount'], axis=1, inplace=False)\n",
    "books_ratings_1 = books_ratings.drop(['Id','Price', 'profileName', 'review/time'], axis=1, inplace=False)\n",
    "\n",
    "books_data_1.rename(columns={'Title': 'title','publishedDate': 'published_date'}, inplace=True)\n",
    "books_ratings_1.rename(columns={'Title': 'title','User_id':'user_id',  'review/score': 'score','review/helpfulness': 'helpfulness', 'review/text': 'text', 'review/summary': 'summary'}, inplace=True)\n",
    "\n",
    "print(list(books_data_1.columns))\n",
    "print(list(books_ratings_1.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load book data for books in book ratings\n",
    "ratings_titles = books_ratings_1['title'].unique()\n",
    "books_data_1 = books_data_1[books_data_1['title'].isin(ratings_titles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert helpfullness to float\n",
    "\n",
    "books_ratings_1['helpfulness'].replace('0/0', 0, inplace=True)\n",
    "\n",
    "help_pct = []\n",
    "help_count = []\n",
    "\n",
    "for i in range(len(books_ratings_1['helpfulness'])):\n",
    "    if books_ratings_1['helpfulness'][i] != 0:\n",
    "        help_pct.append(float(books_ratings_1['helpfulness'][i].split('/')[0])/float(books_ratings_1['helpfulness'][i].split('/')[1]))\n",
    "        help_count.append(float(books_ratings_1['helpfulness'][i].split('/')[1]))\n",
    "    else:\n",
    "        help_pct.append(0)\n",
    "        help_count.append(0)\n",
    "\n",
    "books_ratings_1['helpfulness_pct'] = help_pct\n",
    "books_ratings_1['helpfulness_count'] = help_count\n",
    "\n",
    "# remove helpfullness column\n",
    "books_ratings_1.drop(['helpfulness'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# count unique ids in books_ratings_1\n",
    "books_data_1.dropna(subset=['title'], inplace = True)\n",
    "entry_count = books_ratings_1['title'].value_counts(sort=False)\n",
    "counts_titles = []\n",
    "average_ratings = []\n",
    "for idx, title in enumerate(books_data_1['title']):\n",
    "    if entry_count[title] > 2:\n",
    "        average_ratings.append(books_ratings_1[books_ratings_1['title']==title]['score'].mean())\n",
    "        counts_titles.append(entry_count[title])\n",
    "    else:\n",
    "        average_ratings.append(np.nan)\n",
    "        counts_titles.append(np.nan)\n",
    "\n",
    "books_data_1['ratings_count'] = counts_titles\n",
    "books_data_1['average_rating'] = average_ratings\n",
    "\n",
    "books_data_1.dropna(subset=['ratings_count'], inplace = True)\n",
    "# reset index\n",
    "books_data_1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# remove books with less than 2 ratings from books_ratings_1\n",
    "books_ratings_1 = books_ratings_1[books_ratings_1['title'].isin(books_data_1['title'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2005\n",
      "1      2000\n",
      "2      2005\n",
      "3      1996\n",
      "4      1988\n",
      "       ... \n",
      "431    2001\n",
      "432    2011\n",
      "433    1966\n",
      "434    2003\n",
      "435    2013\n",
      "Name: published_date, Length: 436, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# convert published_date to datetime\n",
    "year = []\n",
    "for date in books_data_1['published_date']:\n",
    "    try:\n",
    "        year.append(date.split('-')[0])\n",
    "    except:\n",
    "        year.append(0)\n",
    "\n",
    "year2 = []\n",
    "for y in year:\n",
    "    try:\n",
    "        year2.append(y.split('*')[0])\n",
    "    except:\n",
    "        year2.append(y)\n",
    "\n",
    "books_data_1['published_date'] = year2\n",
    "\n",
    "# convert published_date to int\n",
    "books_data_1['published_date'] = books_data_1['published_date'].astype(int)\n",
    "\n",
    "print(books_data_1['published_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new folder for clean data\n",
    "import os\n",
    "if not os.path.exists('clean_data'):\n",
    "    os.makedirs('clean_data')\n",
    "\n",
    "# save clean data\n",
    "books_data_1.to_csv('clean_data/books_data_clean.csv')\n",
    "books_ratings_1.to_csv('clean_data/books_rating_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comptool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
