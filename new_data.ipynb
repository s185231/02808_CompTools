{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: VARIABLE=comptools-env\n"
     ]
    }
   ],
   "source": [
    "%env VARIABLE=comptools-env"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:47:23.874637300Z",
     "start_time": "2023-10-30T09:47:23.858803900Z"
    }
   },
   "id": "1836365cafbc0824"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books data has 10 columns with 212404 rows each.\n",
      "Books ratings has 10 columns with 3000000 rows each.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "books_data = pd.read_csv('data/books_data.csv') #, nrows=1000)\n",
    "print(f\"Books data has \" + str(books_data.columns.size) + \" columns with \" + str(books_data.shape[0]) + \" rows each.\")\n",
    "books_ratings = pd.read_csv('data/books_rating.csv') #, nrows=1000)\n",
    "print(f\"Books ratings has \" + str(books_ratings.columns.size) + \" columns with \" + str(books_ratings.shape[0]) + \" rows each.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:49:24.390029200Z",
     "start_time": "2023-10-30T09:47:25.196498400Z"
    }
   },
   "id": "361b23418fb2f778"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books data now only has 5 columns - ['title', 'description', 'authors', 'published_date', 'categories']\n",
      "Books ratings now only has 6 columns - ['title', 'user_id', 'helpfulness', 'score', 'summary', 'text']\n"
     ]
    }
   ],
   "source": [
    "# Titles\n",
    "books_data_1 = books_data.drop(['image', 'previewLink', 'infoLink', 'publisher', 'ratingsCount'], axis=1, inplace=False)\n",
    "books_ratings_1 = books_ratings.drop(['Id','Price', 'profileName', 'review/time'], axis=1, inplace=False)\n",
    "\n",
    "books_data_1.rename(columns={'Title': 'title','publishedDate': 'published_date'}, inplace=True)\n",
    "books_ratings_1.rename(columns={'Title': 'title','User_id':'user_id',  'review/score': 'score','review/helpfulness': 'helpfulness', 'review/text': 'text', 'review/summary': 'summary'}, inplace=True)\n",
    "print(f\"Books data now only has \" + str(books_data_1.columns.size) + \" columns - \" + str(list(books_data_1.columns)))\n",
    "print(f\"Books ratings now only has \" + str(books_ratings_1.columns.size) + \" columns - \" + str(list(books_ratings_1.columns))) \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:49:56.430685800Z",
     "start_time": "2023-10-30T09:49:26.710977800Z"
    }
   },
   "id": "4e683b0b3a4fef0f"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both datasets' titles are now all lowercase and only include letters and spaces.\n"
     ]
    }
   ],
   "source": [
    "#Makes all titles lowercase; then removes any part of the title that includes a parenthesis, and replaces any ampersands with 'and'\n",
    "books_data_1['title'] = books_data_1['title'].map(lambda s: s.lower() if type(s) == str else s)\n",
    "books_data_1['title'] = books_data_1['title'].replace(r\"\\(.*\\)\",\"\", regex=True)\n",
    "books_data_1['title'] = books_data_1['title'].replace(r\"\\&\",\"and\", regex=True)\n",
    "\n",
    "books_ratings_1['title'] = books_ratings_1['title'].map(lambda s: s.lower() if type(s) == str else s)\n",
    "books_ratings_1['title'] = books_ratings_1['title'].replace(r\"\\(.*\\)\",\"\", regex=True)\n",
    "books_ratings_1['title'] = books_ratings_1['title'].replace(r\"\\&\",\"and\", regex=True)\n",
    "\n",
    "#Removes any characters that aren't letters or spaces.\n",
    "books_data_1['title'] = books_data_1['title'].replace(r\"[^a-zA-Z0-9\\s]+\", \"\", regex=True)\n",
    "books_ratings_1['title'] = books_ratings_1['title'].replace(r\"[^a-zA-Z0-9\\s]+\", \"\", regex=True)\n",
    "\n",
    "print(\"Both datasets' titles are now all lowercase and only include letters and spaces.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:50:25.999130300Z",
     "start_time": "2023-10-30T09:50:12.778167900Z"
    }
   },
   "id": "28ac36b6874efe74"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books data has 212404 titles.\n",
      "Dropped 7500 duplicate titles. Now there are only 204904 rows left. \n"
     ]
    }
   ],
   "source": [
    "# keep only unique titles in books_data_1\n",
    "#size of books_data_1\n",
    "prev_size = len(books_data_1['title'])\n",
    "print(f\"Books data has \" + str(len(books_data_1['title'])) + \" titles.\")\n",
    "books_data_1 = books_data_1.drop_duplicates(subset=['title'], keep='first')\n",
    "print(f\"Dropped \" + str(prev_size - len(books_data_1['title'])) + \" duplicate titles. Now there are only \" + str(len(books_data_1['title'])) + \" rows left. \")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:50:30.169414100Z",
     "start_time": "2023-10-30T09:50:28.937063Z"
    }
   },
   "id": "26aa9480ac40b0af"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped based on total duplicity. Books ratings now has 2432035 rows.  -567965 rows.\n",
      "Books ratings has 2432035 rows.\n",
      "Dropped based on duplicate text. Books ratings now has 2064756 rows.  -367279 rows.\n",
      "Dropped based on duplicate summary. Books ratings now has 1987892 rows.  -76864 rows.\n",
      "Dropped based on duplicate title. Books ratings now has 1730384 rows.  -257508 rows.\n"
     ]
    }
   ],
   "source": [
    "#Drop duplicate reviews where same user reviews same book multiple times\n",
    "print(f\"Books ratings has \" + str(len(books_ratings_1['title'])) + \" rows.\")\n",
    "prevRatings = len(books_ratings_1['title'])\n",
    "books_ratings_1.drop_duplicates(keep='first', inplace=True)\n",
    "print(f\"Dropped based on total duplicity. Books ratings now has \" + str(len(books_ratings_1['title'])) + \" rows. \" + \" -\" + str(prevRatings-len(books_ratings_1['title'])) + \" rows.\")\n",
    "prevRatings = len(books_ratings_1['title'])\n",
    "books_ratings_1.drop_duplicates(subset=['user_id', 'title'], keep='first', inplace=True)\n",
    "print(f\"Dropped based on duplicate title. Books ratings now has \" + str(len(books_ratings_1['title'])) + \" rows. \" + \" -\" + str(prevRatings-len(books_ratings_1['title'])) + \" rows.\")\n",
    "prevRatings = len(books_ratings_1['title'])\n",
    "books_ratings_1.drop_duplicates(subset=['user_id', 'text'], keep='first', inplace=True)\n",
    "print(f\"Dropped based on duplicate text. Books ratings now has \" + str(len(books_ratings_1['title'])) + \" rows. \" + \" -\" + str(prevRatings-len(books_ratings_1['title'])) + \" rows.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:51:13.410407700Z",
     "start_time": "2023-10-30T09:50:38.674441Z"
    }
   },
   "id": "b09121723c055517"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Remove NAN titles\n",
    "print(f\"\" + str(books_ratings_1.isnull().sum().sum()) + \" total NAN values present in title\")\n",
    "books_ratings_1 = books_ratings_1.dropna(subset=['title'])\n",
    "print(f\"Now there are \" + str(books_ratings_1.isnull().sum().sum()))\n",
    "\n",
    "print(f\"Now there are \" + str(books_data_1.isnull().sum().sum()))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66b6263402bde5b4"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books_ratings has 1730384 rows.\n",
      "Books_ratings now has 1275993 rows. -454391 rows. \n",
      "Books_data now has an additional column.\n",
      "Index(['title', 'description', 'authors', 'published_date', 'categories',\n",
      "       'n_ratings'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Collect only ratings for books that have received at least 10 ratings.\n",
    "#Add a new column in books_data_1 that counts the number of ratings for each book with a score of at least 10\n",
    "\n",
    "#Note that by removing duplicate reviews first, counting the number of reviews for each book afterward will be more accurate.\n",
    "print(f\"Books_ratings has \" + str(len(books_ratings_1['title'])) + \" rows.\")\n",
    "prev_rows = len(books_ratings_1['title'])\n",
    "\n",
    "n_ratings = books_ratings_1.groupby('title').count()['score']>=10\n",
    "famous_books = n_ratings[n_ratings==True].index\n",
    "books_ratings_1 = books_ratings_1[books_ratings_1['title'].isin(famous_books)]\n",
    "n_ratings_1 = books_ratings_1['title'].value_counts().rename(\"n_ratings\")\n",
    "books_data_1 = books_data_1.merge(n_ratings_1, on='title', how='inner')\n",
    "\n",
    "print(f\"Books_ratings now has \" + str(len(books_ratings_1['title'])) + \" rows. -\" + str(prev_rows - len(books_ratings_1['title'])) + \" rows. \")\n",
    "print(f\"Books_data now has an additional column. (n_ratings)\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:52:28.864155600Z",
     "start_time": "2023-10-30T09:52:21.462970300Z"
    }
   },
   "id": "f30c9015edd25bf1"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books data has 6 columns with 33122 rows each. -0 rows.\n"
     ]
    }
   ],
   "source": [
    "#purge books where n_ratings < 10 (redundant operation)\n",
    "prevBooks = len(books_data_1['title'])\n",
    "books_data_1 = books_data_1[books_data_1['n_ratings']>=10]\n",
    "print(f\"Books data has \" + str(books_data_1.columns.size) + \" columns with \" + str(books_data_1.shape[0]) + \" rows each.\" + \" -\" + str(prevBooks-len(books_data_1['title'])) + \" rows.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:53:21.361418700Z",
     "start_time": "2023-10-30T09:53:21.300261600Z"
    }
   },
   "id": "b13ea696aba6df66"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books ratings has 6 columns with 163761 rows each. -0 rows.\n",
      "3358 users remain who have rated at least 20 books.\n"
     ]
    }
   ],
   "source": [
    "#Remove ratings from users who have rated less than 20 books.\n",
    "prevRatings = len(books_ratings_1['title'])\n",
    "x = books_ratings_1.groupby('user_id').count()['score'] >= 20 # since this is what amazon requires before a user can get recommendations\n",
    "considerable_users = x[x].index\n",
    "books_ratings_1 = books_ratings_1[books_ratings_1['user_id'].isin(considerable_users)]\n",
    "\n",
    "print(f\"Books ratings has \" + str(books_ratings_1.columns.size) + \" columns with \" + str(books_ratings_1.shape[0]) + \" rows each.\" + \" -\" + str(prevRatings-len(books_ratings_1['title'])) + \" rows.\")\n",
    "print(f\"\" + str(len(books_ratings_1['user_id'].value_counts())) + \" users remain who have rated at least 20 books.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T09:57:20.918461500Z",
     "start_time": "2023-10-30T09:57:20.603644600Z"
    }
   },
   "id": "a76984b6b5ece24a"
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books data now has an additional column. (avg_rating)\n"
     ]
    }
   ],
   "source": [
    "avg_rating = books_ratings_1.groupby('title')[\"score\"].mean().rename(\"avg_rating\")\n",
    "books_data_1 = books_data_1.merge(avg_rating, on='title', how='inner')\n",
    "print(f\"Books data now has an additional column. (avg_rating)\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:31:58.905061400Z",
     "start_time": "2023-10-30T12:31:58.236370400Z"
    }
   },
   "id": "b1a05bb19481306b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#\n",
    "def get_n_helpful(x):\n",
    "    if isinstance(x, str) and '/' in x:\n",
    "        num, denom = x.split('/')\n",
    "        return int(denom)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def replace_fraction(x):\n",
    "    if isinstance(x, str) and '/' in x:\n",
    "        num, denom = x.split('/')\n",
    "        if denom == '0':\n",
    "            return 0\n",
    "        else:\n",
    "            return int(num) / int(denom)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "books_ratings_1['helpfulness_count'] = books_ratings_1['helpfulness'].apply(get_n_helpful)\n",
    "books_ratings_1['helpfulness_pct'] = books_ratings_1['helpfulness'].apply(replace_fraction)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac61d5cc6189fc85"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First we had 212404 books and 3000000 ratings.\n",
      "Now we have 33122 books and 163761 ratings. -84.41% books and 94.54% ratings.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists('clean_data'):\n",
    "    os.makedirs('clean_data')\n",
    "\n",
    "# save clean data\n",
    "books_data_1.to_csv('clean_data/books_data_clean.csv', index=False)\n",
    "books_ratings_1.to_csv('clean_data/books_rating_clean.csv', index=False)\n",
    "\n",
    "prevBooks = len(books_data)\n",
    "prevRatings = len(books_ratings)\n",
    "newBooks = len(books_data_1)\n",
    "newRatings = len(books_ratings_1)\n",
    "\n",
    "print(f\"First we had \" + str(prevBooks) + \" books and \" + str(prevRatings) + \" ratings.\")\n",
    "print(f\"Now we have \" + str(newBooks) + \" books and \" + str(newRatings) + \" ratings. -\" + str(round((prevBooks-newBooks)/prevBooks*100,2)) + \"% books and -\" + str(round((prevRatings-newRatings)/prevRatings*100,2)) + \"% ratings.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T10:06:34.536149600Z",
     "start_time": "2023-10-30T10:06:26.826665900Z"
    }
   },
   "id": "e6c5f48a3a619416"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Code from here on down is not saved to the csv file.</h2>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "793f1f3c1f8fe2b0"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books data has 6 columns with 33122 rows each.\n",
      "Books ratings has 6 columns with 163761 rows each.\n"
     ]
    }
   ],
   "source": [
    "books_data_1 = pd.read_csv('clean_data/books_data_clean.csv') #, nrows=1000)\n",
    "print(f\"Books data has \" + str(books_data_1.columns.size) + \" columns with \" + str(books_data_1.shape[0]) + \" rows each.\")\n",
    "books_ratings_1 = pd.read_csv('clean_data/books_rating_clean.csv') #, nrows=1000)\n",
    "print(f\"Books ratings has \" + str(books_ratings_1.columns.size) + \" columns with \" + str(books_ratings_1.shape[0]) + \" rows each.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T10:11:54.766689900Z",
     "start_time": "2023-10-30T10:11:47.625710300Z"
    }
   },
   "id": "346692a420d418e5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "books_ratings_1['user_id'].value_counts()\n",
    "#Looked at the ratings for the top 2 users and found nothing remarkable. The review text is cut off after a small number of words, so it is tough to see if they are automated reviews, as most of them more or less just describe the book rather than the reader's opinion of it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d196d12dafb69ef4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3adc2930a7d3a3cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
