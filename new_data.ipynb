{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: VARIABLE=comptools-env\n"
     ]
    }
   ],
   "source": [
    "%env VARIABLE=comptools-env"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:40:10.422165400Z",
     "start_time": "2023-10-30T12:40:10.120526700Z"
    }
   },
   "id": "1836365cafbc0824"
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books data has 10 columns with 212404 rows each.\n",
      "Books ratings has 10 columns with 3000000 rows each.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "books_data = pd.read_csv('data/books_data.csv') #, nrows=1000)\n",
    "print(f\"Books data has \" + str(books_data.columns.size) + \" columns with \" + str(books_data.shape[0]) + \" rows each.\")\n",
    "books_ratings = pd.read_csv('data/books_rating.csv') #, nrows=1000)\n",
    "print(f\"Books ratings has \" + str(books_ratings.columns.size) + \" columns with \" + str(books_ratings.shape[0]) + \" rows each.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:42:39.074870200Z",
     "start_time": "2023-10-30T12:40:10.151254400Z"
    }
   },
   "id": "361b23418fb2f778"
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books data now only has 5 columns - ['title', 'description', 'authors', 'published_date', 'categories']\n",
      "Books ratings now only has 6 columns - ['title', 'user_id', 'helpfulness', 'score', 'summary', 'text']\n"
     ]
    }
   ],
   "source": [
    "# Titles\n",
    "books_data_1 = books_data.drop(['image', 'previewLink', 'infoLink', 'publisher', 'ratingsCount'], axis=1, inplace=False)\n",
    "books_ratings_1 = books_ratings.drop(['Id','Price', 'profileName', 'review/time'], axis=1, inplace=False)\n",
    "\n",
    "books_data_1.rename(columns={'Title': 'title','publishedDate': 'published_date'}, inplace=True)\n",
    "books_ratings_1.rename(columns={'Title': 'title','User_id':'user_id',  'review/score': 'score','review/helpfulness': 'helpfulness', 'review/text': 'text', 'review/summary': 'summary'}, inplace=True)\n",
    "print(f\"Books data now only has \" + str(books_data_1.columns.size) + \" columns - \" + str(list(books_data_1.columns)))\n",
    "print(f\"Books ratings now only has \" + str(books_ratings_1.columns.size) + \" columns - \" + str(list(books_ratings_1.columns))) \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:43:27.158231500Z",
     "start_time": "2023-10-30T12:42:38.997444900Z"
    }
   },
   "id": "4e683b0b3a4fef0f"
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both datasets' titles are now all lowercase and only include letters and spaces.\n"
     ]
    }
   ],
   "source": [
    "#Makes all titles lowercase; then removes any part of the title that includes a parenthesis, and replaces any ampersands with 'and'\n",
    "books_data_1['title'] = books_data_1['title'].map(lambda s: s.lower() if type(s) == str else s)\n",
    "books_data_1['title'] = books_data_1['title'].replace(r\"\\(.*\\)\",\"\", regex=True)\n",
    "books_data_1['title'] = books_data_1['title'].replace(r\"\\&\",\"and\", regex=True)\n",
    "\n",
    "books_ratings_1['title'] = books_ratings_1['title'].map(lambda s: s.lower() if type(s) == str else s)\n",
    "books_ratings_1['title'] = books_ratings_1['title'].replace(r\"\\(.*\\)\",\"\", regex=True)\n",
    "books_ratings_1['title'] = books_ratings_1['title'].replace(r\"\\&\",\"and\", regex=True)\n",
    "\n",
    "#Removes any characters that aren't letters or spaces.\n",
    "books_data_1['title'] = books_data_1['title'].replace(r\"[^a-zA-Z0-9\\s]+\", \"\", regex=True)\n",
    "books_ratings_1['title'] = books_ratings_1['title'].replace(r\"[^a-zA-Z0-9\\s]+\", \"\", regex=True)\n",
    "\n",
    "print(\"Both datasets' titles are now all lowercase and only include letters and spaces.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:43:51.162778600Z",
     "start_time": "2023-10-30T12:43:27.191130600Z"
    }
   },
   "id": "28ac36b6874efe74"
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books data has 212404 titles.\n",
      "Dropped 7500 duplicate titles. Now there are only 204904 rows left. \n"
     ]
    }
   ],
   "source": [
    "# keep only unique titles in books_data_1\n",
    "#size of books_data_1\n",
    "prev_size = len(books_data_1['title'])\n",
    "print(f\"Books data has \" + str(len(books_data_1['title'])) + \" titles.\")\n",
    "books_data_1 = books_data_1.drop_duplicates(subset=['title'], keep='first')\n",
    "print(f\"Dropped \" + str(prev_size - len(books_data_1['title'])) + \" duplicate titles. Now there are only \" + str(len(books_data_1['title'])) + \" rows left. \")\n",
    "\n",
    "#Remove NAN titles\n",
    "print(f\"\" + str(books_ratings_1['title'].isnull().sum().sum()) + \" total NAN values present in title\")\n",
    "books_ratings_1 = books_ratings_1.dropna(subset=['title'])\n",
    "print(f\"Now there are \" + str(books_ratings_1['title'].isnull().sum().sum()))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:43:53.407896400Z",
     "start_time": "2023-10-30T12:43:51.173844900Z"
    }
   },
   "id": "26aa9480ac40b0af"
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books ratings has 3000000 rows.\n",
      "Dropped based on total duplicity. Books ratings now has 2432035 rows.  -567965 rows.\n",
      "Dropped based on duplicate title. Books ratings now has 2027318 rows.  -404717 rows.\n",
      "Dropped based on duplicate text. Books ratings now has 1748116 rows.  -279202 rows.\n"
     ]
    }
   ],
   "source": [
    "#Drop duplicate reviews where same user reviews same book multiple times\n",
    "print(f\"Books ratings has \" + str(len(books_ratings_1['title'])) + \" rows.\")\n",
    "prevRatings = len(books_ratings_1['title'])\n",
    "books_ratings_1.drop_duplicates(keep='first', inplace=True)\n",
    "print(f\"Dropped based on total duplicity. Books ratings now has \" + str(len(books_ratings_1['title'])) + \" rows. \" + \" -\" + str(prevRatings-len(books_ratings_1['title'])) + \" rows.\")\n",
    "prevRatings = len(books_ratings_1['title'])\n",
    "books_ratings_1.drop_duplicates(subset=['user_id', 'title'], keep='first', inplace=True)\n",
    "print(f\"Dropped based on duplicate title. Books ratings now has \" + str(len(books_ratings_1['title'])) + \" rows. \" + \" -\" + str(prevRatings-len(books_ratings_1['title'])) + \" rows.\")\n",
    "prevRatings = len(books_ratings_1['title'])\n",
    "books_ratings_1.drop_duplicates(subset=['user_id', 'text'], keep='first', inplace=True)\n",
    "print(f\"Dropped based on duplicate text. Books ratings now has \" + str(len(books_ratings_1['title'])) + \" rows. \" + \" -\" + str(prevRatings-len(books_ratings_1['title'])) + \" rows.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:45:02.832303300Z",
     "start_time": "2023-10-30T12:43:53.438245800Z"
    }
   },
   "id": "b09121723c055517"
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books_ratings has 1748097 rows.\n",
      "Books_ratings now has 1287419 rows. -460678 rows. \n",
      "Books_data now has an additional column. (n_ratings)\n"
     ]
    }
   ],
   "source": [
    "#Collect only ratings for books that have received at least 10 ratings.\n",
    "#Add a new column in books_data_1 that counts the number of ratings for each book with a score of at least 10\n",
    "\n",
    "#Note that by removing duplicate reviews first, counting the number of reviews for each book afterward will be more accurate.\n",
    "print(f\"Books_ratings has \" + str(len(books_ratings_1['title'])) + \" rows.\")\n",
    "prev_rows = len(books_ratings_1['title'])\n",
    "\n",
    "n_ratings = books_ratings_1.groupby('title').count()['score']>=10\n",
    "famous_books = n_ratings[n_ratings==True].index\n",
    "books_ratings_1 = books_ratings_1[books_ratings_1['title'].isin(famous_books)]\n",
    "n_ratings_1 = books_ratings_1['title'].value_counts().rename(\"n_ratings\")\n",
    "books_data_1 = books_data_1.merge(n_ratings_1, on='title', how='inner')\n",
    "\n",
    "print(f\"Books_ratings now has \" + str(len(books_ratings_1['title'])) + \" rows. -\" + str(prev_rows - len(books_ratings_1['title'])) + \" rows. \")\n",
    "print(f\"Books_data now has an additional column. (n_ratings)\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:45:10.965218100Z",
     "start_time": "2023-10-30T12:45:05.966782500Z"
    }
   },
   "id": "f30c9015edd25bf1"
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books data has 6 columns with 33446 rows each. -0 rows.\n"
     ]
    }
   ],
   "source": [
    "#purge books where n_ratings < 10 (redundant operation)\n",
    "prevBooks = len(books_data_1['title'])\n",
    "books_data_1 = books_data_1[books_data_1['n_ratings']>=10]\n",
    "print(f\"Books data has \" + str(books_data_1.columns.size) + \" columns with \" + str(books_data_1.shape[0]) + \" rows each.\" + \" -\" + str(prevBooks-len(books_data_1['title'])) + \" rows.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:45:10.990323900Z",
     "start_time": "2023-10-30T12:45:10.965218100Z"
    }
   },
   "id": "b13ea696aba6df66"
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books ratings has 6 columns with 168980 rows each. -1118439 rows.\n",
      "3417 users remain who have rated at least 20 books.\n"
     ]
    }
   ],
   "source": [
    "#Remove ratings from users who have rated less than 20 books.\n",
    "prevRatings = len(books_ratings_1['title'])\n",
    "x = books_ratings_1.groupby('user_id').count()['score'] >= 20 # since this is what amazon requires before a user can get recommendations\n",
    "considerable_users = x[x].index\n",
    "books_ratings_1 = books_ratings_1[books_ratings_1['user_id'].isin(considerable_users)]\n",
    "\n",
    "print(f\"Books ratings has \" + str(books_ratings_1.shape[0]) + \" rows.\" + \" -\" + str(prevRatings-len(books_ratings_1['title'])) + \" rows.\")\n",
    "print(f\"\" + str(len(books_ratings_1['user_id'].value_counts())) + \" users remain who have rated at least 20 books.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:45:14.355160600Z",
     "start_time": "2023-10-30T12:45:11.006088800Z"
    }
   },
   "id": "a76984b6b5ece24a"
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books data now has an additional column. (avg_rating)\n"
     ]
    }
   ],
   "source": [
    "avg_rating = books_ratings_1.groupby('title')[\"score\"].mean().rename(\"avg_rating\")\n",
    "books_data_1 = books_data_1.merge(avg_rating, on='title', how='inner')\n",
    "print(f\"Books data now has an additional column. (avg_rating)\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:45:14.612335Z",
     "start_time": "2023-10-30T12:45:14.395517Z"
    }
   },
   "id": "b1a05bb19481306b"
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "#\n",
    "def get_n_helpful(x):\n",
    "    if isinstance(x, str) and '/' in x:\n",
    "        num, denom = x.split('/')\n",
    "        return int(denom)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def replace_fraction(x):\n",
    "    if isinstance(x, str) and '/' in x:\n",
    "        num, denom = x.split('/')\n",
    "        if denom == '0':\n",
    "            return 0\n",
    "        else:\n",
    "            return int(num) / int(denom)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "books_ratings_1['helpfulness_count'] = books_ratings_1['helpfulness'].apply(get_n_helpful)\n",
    "books_ratings_1['helpfulness_pct'] = books_ratings_1['helpfulness'].apply(replace_fraction)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:45:15.022360300Z",
     "start_time": "2023-10-30T12:45:14.617847800Z"
    }
   },
   "id": "ac61d5cc6189fc85"
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First we had 212404 books and 3000000 ratings.\n",
      "Now we have 25402 books and 168980 ratings. -88.04% books and -94.37% ratings.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists('clean_data'):\n",
    "    os.makedirs('clean_data')\n",
    "\n",
    "# save clean data\n",
    "books_data_1.to_csv('clean_data/books_data_clean.csv', index=False)\n",
    "books_ratings_1.to_csv('clean_data/books_rating_clean.csv', index=False)\n",
    "\n",
    "prevBooks = len(books_data)\n",
    "prevRatings = len(books_ratings)\n",
    "newBooks = len(books_data_1)\n",
    "newRatings = len(books_ratings_1)\n",
    "\n",
    "print(f\"First we had \" + str(prevBooks) + \" books and \" + str(prevRatings) + \" ratings.\")\n",
    "print(f\"Now we have \" + str(newBooks) + \" books and \" + str(newRatings) + \" ratings. -\" + str(round((prevBooks-newBooks)/prevBooks*100,2)) + \"% books and -\" + str(round((prevRatings-newRatings)/prevRatings*100,2)) + \"% ratings.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:45:28.569544400Z",
     "start_time": "2023-10-30T12:45:15.020853200Z"
    }
   },
   "id": "e6c5f48a3a619416"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2>Code from here on down is not saved to the csv file.</h2>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "793f1f3c1f8fe2b0"
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Books data has 7 columns with 25402 rows each.\n",
      "Books ratings has 8 columns with 168980 rows each.\n"
     ]
    }
   ],
   "source": [
    "books_data_1 = pd.read_csv('clean_data/books_data_clean.csv') #, nrows=1000)\n",
    "print(f\"Books data has \" + str(books_data_1.columns.size) + \" columns with \" + str(books_data_1.shape[0]) + \" rows each.\")\n",
    "books_ratings_1 = pd.read_csv('clean_data/books_rating_clean.csv') #, nrows=1000)\n",
    "print(f\"Books ratings has \" + str(books_ratings_1.columns.size) + \" columns with \" + str(books_ratings_1.shape[0]) + \" rows each.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:45:40.770400200Z",
     "start_time": "2023-10-30T12:45:28.569544400Z"
    }
   },
   "id": "346692a420d418e5"
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "data": {
      "text/plain": "user_id\nAFVQZQ8PW0L       1963\nA14OJS0VWMOSWO    1740\nA1X8VZWTOG8IS6     765\nA1K1JW1C5CUSUZ     677\nA2F6N60Z96CAJI     557\n                  ... \nACK3TZEDR258N       20\nAJN24TVEGZEI4       20\nA1X9YMZQ2XXDCI      20\nA31Y9DLKVASJQY      20\nA2XZW1WV871DIO      20\nName: count, Length: 3417, dtype: int64"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_ratings_1['user_id'].value_counts()\n",
    "#Looked at the ratings for the top 2 users and found nothing remarkable. The review text is cut off after a small number of words, so it is tough to see if they are automated reviews, as most of them more or less just describe the book rather than the reader's opinion of it."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:45:40.934387100Z",
     "start_time": "2023-10-30T12:45:40.760390600Z"
    }
   },
   "id": "d196d12dafb69ef4"
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "summary\nexciting thriller                          12\nexciting romantic suspense                  8\ndeep character study                        6\nA good read                                 6\nexciting police procedural                  5\n                                           ..\nhaunting classic war story                  1\nfascinating historical mystery              1\nengaging espionage romance                  1\nexciting premise                            1\nfantastic paranormal serial killer tale     1\nName: count, Length: 1779, dtype: int64"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract all books rated by the top user by number of ratings, to check for duplicate reviews (spam)\n",
    "books_ratings_1[books_ratings_1['user_id'] == 'AFVQZQ8PW0L']['summary'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T12:52:49.955780300Z",
     "start_time": "2023-10-30T12:52:49.880242600Z"
    }
   },
   "id": "3adc2930a7d3a3cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b728934bb6033dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
